{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Conv2D, MaxPooling2D\n",
    "from keras.layers import Dropout, BatchNormalization, LeakyReLU, Activation\n",
    "\n",
    "from keras import optimizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "# Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        'data/FER 2013 default/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical'\n",
    "        )\n",
    "\n",
    "# Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        'data/FER 2013 default/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-03 14:35:01.580474: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/roma/anaconda3/envs/deep_learning/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "emotion_model.add(Conv2D(32, kernel_size=(5, 5), activation='elu', input_shape=(48, 48, 1), padding='same', kernel_initializer='he_normal'))\n",
    "emotion_model.add(BatchNormalization(name='batchnorm_1'))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(5, 5), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.4))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(5, 5), activation='elu', padding='same', kernel_initializer='he_normal'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(5, 5), activation='relu', padding='same', kernel_initializer='he_normal'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.4))\n",
    "\n",
    "# this converts our 3D feature maps to 1D feature vectors\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='elu', kernel_initializer='he_normal'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    min_delta=0.00005,\n",
    "    patience=11,\n",
    "    verbose=1,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = ReduceLROnPlateau(\n",
    "    monitor='val_accuracy',\n",
    "    factor=0.5,\n",
    "    patience=7,\n",
    "    min_lr=1e-7,\n",
    "    verbose=1,\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    early_stopping,\n",
    "    lr_scheduler,\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/nv527ffd4sn4f92077l2twqr0000gn/T/ipykernel_66650/131353881.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 270s 602ms/step - loss: 2.0028 - accuracy: 0.2549 - val_loss: 1.6482 - val_accuracy: 0.3467 - lr: 1.0000e-04\n",
      "Epoch 2/200\n",
      "448/448 [==============================] - 264s 590ms/step - loss: 1.7086 - accuracy: 0.3178 - val_loss: 1.5701 - val_accuracy: 0.3934 - lr: 1.0000e-04\n",
      "Epoch 3/200\n",
      "448/448 [==============================] - 267s 595ms/step - loss: 1.6429 - accuracy: 0.3560 - val_loss: 1.5449 - val_accuracy: 0.4081 - lr: 1.0000e-04\n",
      "Epoch 4/200\n",
      "448/448 [==============================] - 270s 602ms/step - loss: 1.5995 - accuracy: 0.3712 - val_loss: 1.6103 - val_accuracy: 0.4180 - lr: 1.0000e-04\n",
      "Epoch 5/200\n",
      "448/448 [==============================] - 271s 606ms/step - loss: 1.5563 - accuracy: 0.3927 - val_loss: 1.6206 - val_accuracy: 0.4210 - lr: 1.0000e-04\n",
      "Epoch 6/200\n",
      "448/448 [==============================] - 276s 616ms/step - loss: 1.5218 - accuracy: 0.4062 - val_loss: 1.4621 - val_accuracy: 0.4616 - lr: 1.0000e-04\n",
      "Epoch 7/200\n",
      "448/448 [==============================] - 276s 615ms/step - loss: 1.4894 - accuracy: 0.4213 - val_loss: 1.4985 - val_accuracy: 0.4697 - lr: 1.0000e-04\n",
      "Epoch 8/200\n",
      "448/448 [==============================] - 273s 609ms/step - loss: 1.4501 - accuracy: 0.4399 - val_loss: 1.5160 - val_accuracy: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 9/200\n",
      "448/448 [==============================] - 269s 600ms/step - loss: 1.4233 - accuracy: 0.4525 - val_loss: 1.5020 - val_accuracy: 0.4948 - lr: 1.0000e-04\n",
      "Epoch 10/200\n",
      "448/448 [==============================] - 290s 647ms/step - loss: 1.3968 - accuracy: 0.4653 - val_loss: 1.4879 - val_accuracy: 0.4946 - lr: 1.0000e-04\n",
      "Epoch 11/200\n",
      "448/448 [==============================] - 284s 634ms/step - loss: 1.3638 - accuracy: 0.4755 - val_loss: 1.6666 - val_accuracy: 0.4922 - lr: 1.0000e-04\n",
      "Epoch 12/200\n",
      "448/448 [==============================] - 275s 614ms/step - loss: 1.3414 - accuracy: 0.4845 - val_loss: 1.6957 - val_accuracy: 0.4901 - lr: 1.0000e-04\n",
      "Epoch 13/200\n",
      "448/448 [==============================] - 284s 633ms/step - loss: 1.3141 - accuracy: 0.4977 - val_loss: 1.5413 - val_accuracy: 0.5082 - lr: 1.0000e-04\n",
      "Epoch 14/200\n",
      "448/448 [==============================] - 278s 621ms/step - loss: 1.2925 - accuracy: 0.5062 - val_loss: 1.6618 - val_accuracy: 0.5045 - lr: 1.0000e-04\n",
      "Epoch 15/200\n",
      "448/448 [==============================] - 275s 614ms/step - loss: 1.2604 - accuracy: 0.5204 - val_loss: 1.7466 - val_accuracy: 0.5045 - lr: 1.0000e-04\n",
      "Epoch 16/200\n",
      "448/448 [==============================] - 285s 636ms/step - loss: 1.2428 - accuracy: 0.5306 - val_loss: 1.7028 - val_accuracy: 0.5179 - lr: 1.0000e-04\n",
      "Epoch 17/200\n",
      "448/448 [==============================] - 285s 637ms/step - loss: 1.2180 - accuracy: 0.5398 - val_loss: 1.7439 - val_accuracy: 0.5121 - lr: 1.0000e-04\n",
      "Epoch 18/200\n",
      "448/448 [==============================] - 292s 652ms/step - loss: 1.1903 - accuracy: 0.5463 - val_loss: 1.5804 - val_accuracy: 0.5299 - lr: 1.0000e-04\n",
      "Epoch 19/200\n",
      "448/448 [==============================] - 307s 685ms/step - loss: 1.1722 - accuracy: 0.5581 - val_loss: 1.5891 - val_accuracy: 0.5409 - lr: 1.0000e-04\n",
      "Epoch 20/200\n",
      "448/448 [==============================] - 301s 673ms/step - loss: 1.1472 - accuracy: 0.5660 - val_loss: 1.6438 - val_accuracy: 0.5442 - lr: 1.0000e-04\n",
      "Epoch 21/200\n",
      "448/448 [==============================] - 295s 658ms/step - loss: 1.1276 - accuracy: 0.5748 - val_loss: 1.5806 - val_accuracy: 0.5428 - lr: 1.0000e-04\n",
      "Epoch 22/200\n",
      "448/448 [==============================] - 297s 662ms/step - loss: 1.1023 - accuracy: 0.5846 - val_loss: 1.4729 - val_accuracy: 0.5607 - lr: 1.0000e-04\n",
      "Epoch 23/200\n",
      "448/448 [==============================] - 302s 673ms/step - loss: 1.0768 - accuracy: 0.5916 - val_loss: 1.6662 - val_accuracy: 0.5465 - lr: 1.0000e-04\n",
      "Epoch 24/200\n",
      "448/448 [==============================] - 304s 677ms/step - loss: 1.0619 - accuracy: 0.6000 - val_loss: 1.5032 - val_accuracy: 0.5629 - lr: 1.0000e-04\n",
      "Epoch 25/200\n",
      "448/448 [==============================] - 299s 667ms/step - loss: 1.0349 - accuracy: 0.6089 - val_loss: 1.6427 - val_accuracy: 0.5565 - lr: 1.0000e-04\n",
      "Epoch 26/200\n",
      "448/448 [==============================] - 415s 927ms/step - loss: 1.0161 - accuracy: 0.6185 - val_loss: 1.5238 - val_accuracy: 0.5725 - lr: 1.0000e-04\n",
      "Epoch 27/200\n",
      "448/448 [==============================] - 321s 717ms/step - loss: 0.9906 - accuracy: 0.6295 - val_loss: 1.4550 - val_accuracy: 0.5780 - lr: 1.0000e-04\n",
      "Epoch 28/200\n",
      "448/448 [==============================] - 353s 788ms/step - loss: 0.9699 - accuracy: 0.6375 - val_loss: 1.5177 - val_accuracy: 0.5693 - lr: 1.0000e-04\n",
      "Epoch 29/200\n",
      "448/448 [==============================] - 384s 857ms/step - loss: 0.9540 - accuracy: 0.6412 - val_loss: 1.3860 - val_accuracy: 0.5820 - lr: 1.0000e-04\n",
      "Epoch 30/200\n",
      "448/448 [==============================] - 367s 820ms/step - loss: 0.9256 - accuracy: 0.6559 - val_loss: 1.5676 - val_accuracy: 0.5716 - lr: 1.0000e-04\n",
      "Epoch 31/200\n",
      "448/448 [==============================] - 295s 659ms/step - loss: 0.9026 - accuracy: 0.6633 - val_loss: 1.4826 - val_accuracy: 0.5660 - lr: 1.0000e-04\n",
      "Epoch 32/200\n",
      "448/448 [==============================] - 291s 649ms/step - loss: 0.8814 - accuracy: 0.6715 - val_loss: 1.4710 - val_accuracy: 0.5777 - lr: 1.0000e-04\n",
      "Epoch 33/200\n",
      "448/448 [==============================] - 294s 657ms/step - loss: 0.8628 - accuracy: 0.6800 - val_loss: 1.6119 - val_accuracy: 0.5734 - lr: 1.0000e-04\n",
      "Epoch 34/200\n",
      "448/448 [==============================] - 294s 655ms/step - loss: 0.8380 - accuracy: 0.6866 - val_loss: 1.5314 - val_accuracy: 0.5752 - lr: 1.0000e-04\n",
      "Epoch 35/200\n",
      "448/448 [==============================] - 296s 660ms/step - loss: 0.8173 - accuracy: 0.6961 - val_loss: 1.5266 - val_accuracy: 0.5815 - lr: 1.0000e-04\n",
      "Epoch 36/200\n",
      "448/448 [==============================] - 310s 693ms/step - loss: 0.8032 - accuracy: 0.6975 - val_loss: 1.4440 - val_accuracy: 0.5887 - lr: 1.0000e-04\n",
      "Epoch 37/200\n",
      "448/448 [==============================] - 304s 677ms/step - loss: 0.7880 - accuracy: 0.7075 - val_loss: 1.4555 - val_accuracy: 0.5936 - lr: 1.0000e-04\n",
      "Epoch 38/200\n",
      "448/448 [==============================] - 301s 673ms/step - loss: 0.7582 - accuracy: 0.7154 - val_loss: 1.5722 - val_accuracy: 0.5862 - lr: 1.0000e-04\n",
      "Epoch 39/200\n",
      "448/448 [==============================] - 297s 662ms/step - loss: 0.7473 - accuracy: 0.7198 - val_loss: 1.5250 - val_accuracy: 0.5829 - lr: 1.0000e-04\n",
      "Epoch 40/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.7349 - accuracy: 0.7284 - val_loss: 1.4831 - val_accuracy: 0.5917 - lr: 1.0000e-04\n",
      "Epoch 41/200\n",
      "448/448 [==============================] - 271s 606ms/step - loss: 0.7128 - accuracy: 0.7335 - val_loss: 1.5267 - val_accuracy: 0.5914 - lr: 1.0000e-04\n",
      "Epoch 42/200\n",
      "448/448 [==============================] - 279s 623ms/step - loss: 0.6945 - accuracy: 0.7432 - val_loss: 1.6077 - val_accuracy: 0.5838 - lr: 1.0000e-04\n",
      "Epoch 43/200\n",
      "448/448 [==============================] - 278s 621ms/step - loss: 0.6751 - accuracy: 0.7511 - val_loss: 1.5318 - val_accuracy: 0.5954 - lr: 1.0000e-04\n",
      "Epoch 44/200\n",
      "448/448 [==============================] - 279s 622ms/step - loss: 0.6557 - accuracy: 0.7549 - val_loss: 1.6366 - val_accuracy: 0.5843 - lr: 1.0000e-04\n",
      "Epoch 45/200\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.6397 - accuracy: 0.7645 - val_loss: 1.5907 - val_accuracy: 0.5898 - lr: 1.0000e-04\n",
      "Epoch 46/200\n",
      "448/448 [==============================] - 272s 607ms/step - loss: 0.6184 - accuracy: 0.7678 - val_loss: 1.5452 - val_accuracy: 0.6023 - lr: 1.0000e-04\n",
      "Epoch 47/200\n",
      "448/448 [==============================] - 270s 602ms/step - loss: 0.6085 - accuracy: 0.7752 - val_loss: 1.5755 - val_accuracy: 0.5972 - lr: 1.0000e-04\n",
      "Epoch 48/200\n",
      "448/448 [==============================] - 269s 601ms/step - loss: 0.5931 - accuracy: 0.7812 - val_loss: 1.6681 - val_accuracy: 0.5979 - lr: 1.0000e-04\n",
      "Epoch 49/200\n",
      "448/448 [==============================] - 270s 602ms/step - loss: 0.5869 - accuracy: 0.7801 - val_loss: 1.5868 - val_accuracy: 0.6004 - lr: 1.0000e-04\n",
      "Epoch 50/200\n",
      "448/448 [==============================] - 269s 601ms/step - loss: 0.5639 - accuracy: 0.7892 - val_loss: 1.6224 - val_accuracy: 0.6004 - lr: 1.0000e-04\n",
      "Epoch 51/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.5476 - accuracy: 0.7983 - val_loss: 1.5554 - val_accuracy: 0.5964 - lr: 1.0000e-04\n",
      "Epoch 52/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.5363 - accuracy: 0.8019 - val_loss: 1.6340 - val_accuracy: 0.5919 - lr: 1.0000e-04\n",
      "Epoch 53/200\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.5303 - accuracy: 0.8040\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.5303 - accuracy: 0.8040 - val_loss: 1.6360 - val_accuracy: 0.5949 - lr: 1.0000e-04\n",
      "Epoch 54/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.4646 - accuracy: 0.8289 - val_loss: 1.6815 - val_accuracy: 0.6030 - lr: 5.0000e-05\n",
      "Epoch 55/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.4572 - accuracy: 0.8313 - val_loss: 1.6307 - val_accuracy: 0.6060 - lr: 5.0000e-05\n",
      "Epoch 56/200\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.4417 - accuracy: 0.8376 - val_loss: 1.7146 - val_accuracy: 0.6028 - lr: 5.0000e-05\n",
      "Epoch 57/200\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.4356 - accuracy: 0.8404 - val_loss: 1.6698 - val_accuracy: 0.6037 - lr: 5.0000e-05\n",
      "Epoch 58/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.4263 - accuracy: 0.8418 - val_loss: 1.7183 - val_accuracy: 0.6032 - lr: 5.0000e-05\n",
      "Epoch 59/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.4268 - accuracy: 0.8418 - val_loss: 1.6763 - val_accuracy: 0.6059 - lr: 5.0000e-05\n",
      "Epoch 60/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.4143 - accuracy: 0.8459 - val_loss: 1.6332 - val_accuracy: 0.6098 - lr: 5.0000e-05\n",
      "Epoch 61/200\n",
      "448/448 [==============================] - 270s 604ms/step - loss: 0.4022 - accuracy: 0.8538 - val_loss: 1.6935 - val_accuracy: 0.6071 - lr: 5.0000e-05\n",
      "Epoch 62/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.4015 - accuracy: 0.8528 - val_loss: 1.6745 - val_accuracy: 0.6090 - lr: 5.0000e-05\n",
      "Epoch 63/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.3881 - accuracy: 0.8597 - val_loss: 1.7056 - val_accuracy: 0.6060 - lr: 5.0000e-05\n",
      "Epoch 64/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.3838 - accuracy: 0.8598 - val_loss: 1.7448 - val_accuracy: 0.6048 - lr: 5.0000e-05\n",
      "Epoch 65/200\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.3821 - accuracy: 0.8585 - val_loss: 1.7701 - val_accuracy: 0.6032 - lr: 5.0000e-05\n",
      "Epoch 66/200\n",
      "448/448 [==============================] - 272s 607ms/step - loss: 0.3786 - accuracy: 0.8600 - val_loss: 1.6887 - val_accuracy: 0.6133 - lr: 5.0000e-05\n",
      "Epoch 67/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.3640 - accuracy: 0.8664 - val_loss: 1.7554 - val_accuracy: 0.6067 - lr: 5.0000e-05\n",
      "Epoch 68/200\n",
      "448/448 [==============================] - 270s 604ms/step - loss: 0.3611 - accuracy: 0.8662 - val_loss: 1.7592 - val_accuracy: 0.6088 - lr: 5.0000e-05\n",
      "Epoch 69/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.3571 - accuracy: 0.8704 - val_loss: 1.8524 - val_accuracy: 0.6014 - lr: 5.0000e-05\n",
      "Epoch 70/200\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.3544 - accuracy: 0.8695 - val_loss: 1.7654 - val_accuracy: 0.6045 - lr: 5.0000e-05\n",
      "Epoch 71/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.3462 - accuracy: 0.8721 - val_loss: 1.7673 - val_accuracy: 0.6039 - lr: 5.0000e-05\n",
      "Epoch 72/200\n",
      "448/448 [==============================] - 270s 603ms/step - loss: 0.3448 - accuracy: 0.8701 - val_loss: 1.8026 - val_accuracy: 0.6094 - lr: 5.0000e-05\n",
      "Epoch 73/200\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.3360 - accuracy: 0.8781\n",
      "Epoch 73: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "448/448 [==============================] - 271s 606ms/step - loss: 0.3360 - accuracy: 0.8781 - val_loss: 1.7925 - val_accuracy: 0.6116 - lr: 5.0000e-05\n",
      "Epoch 74/200\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.3180 - accuracy: 0.8828 - val_loss: 1.7870 - val_accuracy: 0.6102 - lr: 2.5000e-05\n",
      "Epoch 75/200\n",
      "448/448 [==============================] - 271s 605ms/step - loss: 0.3172 - accuracy: 0.8849 - val_loss: 1.7887 - val_accuracy: 0.6102 - lr: 2.5000e-05\n",
      "Epoch 76/200\n",
      "448/448 [==============================] - 270s 604ms/step - loss: 0.3095 - accuracy: 0.8859 - val_loss: 1.7845 - val_accuracy: 0.6110 - lr: 2.5000e-05\n",
      "Epoch 77/200\n",
      "448/448 [==============================] - ETA: 0s - loss: 0.3015 - accuracy: 0.8915Restoring model weights from the end of the best epoch: 66.\n",
      "448/448 [==============================] - 271s 604ms/step - loss: 0.3015 - accuracy: 0.8915 - val_loss: 1.8161 - val_accuracy: 0.6119 - lr: 2.5000e-05\n",
      "Epoch 77: early stopping\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network/model\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=200,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64,\n",
    "        callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure in jason file\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model_3.2_epochs77.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save trained model weight in .h5 file\n",
    "emotion_model.save_weights('emotion_model_3.2_epochs77.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
