{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#import scikitplot\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n",
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        'data/FER 2013 default/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical'\n",
    "        )\n",
    "\n",
    "# Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        'data/FER 2013 default/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 17:24:56.832828: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/roma/anaconda3/envs/deep_learning/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# create model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "# the model so far outputs 3D feature maps (height, width, features)\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "# this converts our 3D feature maps to 1D feature vectors\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))\n",
    "\n",
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cb/nv527ffd4sn4f92077l2twqr0000gn/T/ipykernel_59379/957706480.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 74s 165ms/step - loss: 0.3435 - accuracy: 0.8776 - val_loss: 1.2452 - val_accuracy: 0.6179\n",
      "Epoch 2/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.3376 - accuracy: 0.8796 - val_loss: 1.2691 - val_accuracy: 0.6145\n",
      "Epoch 3/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.3243 - accuracy: 0.8842 - val_loss: 1.2860 - val_accuracy: 0.6159\n",
      "Epoch 4/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.3206 - accuracy: 0.8843 - val_loss: 1.2926 - val_accuracy: 0.6183\n",
      "Epoch 5/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.3024 - accuracy: 0.8928 - val_loss: 1.2950 - val_accuracy: 0.6144\n",
      "Epoch 6/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.3080 - accuracy: 0.8897 - val_loss: 1.3021 - val_accuracy: 0.6161\n",
      "Epoch 7/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.2880 - accuracy: 0.8975 - val_loss: 1.3382 - val_accuracy: 0.6152\n",
      "Epoch 8/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.2845 - accuracy: 0.8994 - val_loss: 1.3256 - val_accuracy: 0.6113\n",
      "Epoch 9/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.2828 - accuracy: 0.8989 - val_loss: 1.3075 - val_accuracy: 0.6150\n",
      "Epoch 10/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2641 - accuracy: 0.9068 - val_loss: 1.3318 - val_accuracy: 0.6122\n",
      "Epoch 11/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2604 - accuracy: 0.9063 - val_loss: 1.3517 - val_accuracy: 0.6140\n",
      "Epoch 12/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.2592 - accuracy: 0.9087 - val_loss: 1.3361 - val_accuracy: 0.6182\n",
      "Epoch 13/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2472 - accuracy: 0.9121 - val_loss: 1.3674 - val_accuracy: 0.6179\n",
      "Epoch 14/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2447 - accuracy: 0.9125 - val_loss: 1.3660 - val_accuracy: 0.6110\n",
      "Epoch 15/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2381 - accuracy: 0.9151 - val_loss: 1.3861 - val_accuracy: 0.6184\n",
      "Epoch 16/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2406 - accuracy: 0.9142 - val_loss: 1.3835 - val_accuracy: 0.6187\n",
      "Epoch 17/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2291 - accuracy: 0.9191 - val_loss: 1.4149 - val_accuracy: 0.6150\n",
      "Epoch 18/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2182 - accuracy: 0.9208 - val_loss: 1.4184 - val_accuracy: 0.6154\n",
      "Epoch 19/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2215 - accuracy: 0.9207 - val_loss: 1.3831 - val_accuracy: 0.6196\n",
      "Epoch 20/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2166 - accuracy: 0.9242 - val_loss: 1.4090 - val_accuracy: 0.6170\n",
      "Epoch 21/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2146 - accuracy: 0.9237 - val_loss: 1.4112 - val_accuracy: 0.6158\n",
      "Epoch 22/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2121 - accuracy: 0.9250 - val_loss: 1.4536 - val_accuracy: 0.6218\n",
      "Epoch 23/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.2056 - accuracy: 0.9266 - val_loss: 1.4287 - val_accuracy: 0.6124\n",
      "Epoch 24/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.1982 - accuracy: 0.9304 - val_loss: 1.4380 - val_accuracy: 0.6198\n",
      "Epoch 25/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.1964 - accuracy: 0.9315 - val_loss: 1.4583 - val_accuracy: 0.6180\n",
      "Epoch 26/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.1897 - accuracy: 0.9340 - val_loss: 1.4973 - val_accuracy: 0.6165\n",
      "Epoch 27/200\n",
      "448/448 [==============================] - 72s 161ms/step - loss: 0.1873 - accuracy: 0.9351 - val_loss: 1.4763 - val_accuracy: 0.6190\n",
      "Epoch 28/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1870 - accuracy: 0.9346 - val_loss: 1.4715 - val_accuracy: 0.6204\n",
      "Epoch 29/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1802 - accuracy: 0.9369 - val_loss: 1.4667 - val_accuracy: 0.6148\n",
      "Epoch 30/200\n",
      "448/448 [==============================] - 73s 162ms/step - loss: 0.1789 - accuracy: 0.9372 - val_loss: 1.4753 - val_accuracy: 0.6194\n",
      "Epoch 31/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1737 - accuracy: 0.9405 - val_loss: 1.5028 - val_accuracy: 0.6152\n",
      "Epoch 32/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1752 - accuracy: 0.9381 - val_loss: 1.5040 - val_accuracy: 0.6191\n",
      "Epoch 33/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1652 - accuracy: 0.9422 - val_loss: 1.5247 - val_accuracy: 0.6190\n",
      "Epoch 34/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1661 - accuracy: 0.9414 - val_loss: 1.5407 - val_accuracy: 0.6218\n",
      "Epoch 35/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1686 - accuracy: 0.9415 - val_loss: 1.5047 - val_accuracy: 0.6123\n",
      "Epoch 36/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1592 - accuracy: 0.9455 - val_loss: 1.5308 - val_accuracy: 0.6193\n",
      "Epoch 37/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1604 - accuracy: 0.9449 - val_loss: 1.5464 - val_accuracy: 0.6141\n",
      "Epoch 38/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1547 - accuracy: 0.9483 - val_loss: 1.5285 - val_accuracy: 0.6165\n",
      "Epoch 39/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1596 - accuracy: 0.9429 - val_loss: 1.5455 - val_accuracy: 0.6172\n",
      "Epoch 40/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1505 - accuracy: 0.9467 - val_loss: 1.5647 - val_accuracy: 0.6218\n",
      "Epoch 41/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1490 - accuracy: 0.9484 - val_loss: 1.5584 - val_accuracy: 0.6184\n",
      "Epoch 42/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1471 - accuracy: 0.9488 - val_loss: 1.5835 - val_accuracy: 0.6183\n",
      "Epoch 43/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1494 - accuracy: 0.9476 - val_loss: 1.5653 - val_accuracy: 0.6161\n",
      "Epoch 44/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1474 - accuracy: 0.9481 - val_loss: 1.5709 - val_accuracy: 0.6184\n",
      "Epoch 45/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1449 - accuracy: 0.9501 - val_loss: 1.5635 - val_accuracy: 0.6217\n",
      "Epoch 46/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1430 - accuracy: 0.9506 - val_loss: 1.5497 - val_accuracy: 0.6173\n",
      "Epoch 47/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1416 - accuracy: 0.9506 - val_loss: 1.5544 - val_accuracy: 0.6155\n",
      "Epoch 48/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1361 - accuracy: 0.9540 - val_loss: 1.5748 - val_accuracy: 0.6186\n",
      "Epoch 49/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1391 - accuracy: 0.9514 - val_loss: 1.5836 - val_accuracy: 0.6158\n",
      "Epoch 50/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1302 - accuracy: 0.9553 - val_loss: 1.5904 - val_accuracy: 0.6183\n",
      "Epoch 51/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.1325 - accuracy: 0.9538 - val_loss: 1.5990 - val_accuracy: 0.6175\n",
      "Epoch 52/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.1354 - accuracy: 0.9538 - val_loss: 1.5642 - val_accuracy: 0.6162\n",
      "Epoch 53/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1279 - accuracy: 0.9557 - val_loss: 1.6085 - val_accuracy: 0.6191\n",
      "Epoch 54/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1273 - accuracy: 0.9556 - val_loss: 1.5952 - val_accuracy: 0.6183\n",
      "Epoch 55/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1308 - accuracy: 0.9536 - val_loss: 1.6253 - val_accuracy: 0.6150\n",
      "Epoch 56/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1290 - accuracy: 0.9557 - val_loss: 1.6066 - val_accuracy: 0.6143\n",
      "Epoch 57/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1221 - accuracy: 0.9577 - val_loss: 1.6822 - val_accuracy: 0.6218\n",
      "Epoch 58/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1195 - accuracy: 0.9580 - val_loss: 1.6232 - val_accuracy: 0.6162\n",
      "Epoch 59/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.1206 - accuracy: 0.9591 - val_loss: 1.6169 - val_accuracy: 0.6162\n",
      "Epoch 60/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1247 - accuracy: 0.9565 - val_loss: 1.6773 - val_accuracy: 0.6186\n",
      "Epoch 61/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.1203 - accuracy: 0.9571 - val_loss: 1.6481 - val_accuracy: 0.6173\n",
      "Epoch 62/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1192 - accuracy: 0.9583 - val_loss: 1.6332 - val_accuracy: 0.6184\n",
      "Epoch 63/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1205 - accuracy: 0.9601 - val_loss: 1.6627 - val_accuracy: 0.6228\n",
      "Epoch 64/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1181 - accuracy: 0.9582 - val_loss: 1.6381 - val_accuracy: 0.6219\n",
      "Epoch 65/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1175 - accuracy: 0.9581 - val_loss: 1.6152 - val_accuracy: 0.6200\n",
      "Epoch 66/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1126 - accuracy: 0.9622 - val_loss: 1.6701 - val_accuracy: 0.6191\n",
      "Epoch 67/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1150 - accuracy: 0.9591 - val_loss: 1.6843 - val_accuracy: 0.6145\n",
      "Epoch 68/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1098 - accuracy: 0.9611 - val_loss: 1.6681 - val_accuracy: 0.6190\n",
      "Epoch 69/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.1066 - accuracy: 0.9648 - val_loss: 1.6787 - val_accuracy: 0.6205\n",
      "Epoch 70/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1135 - accuracy: 0.9598 - val_loss: 1.6877 - val_accuracy: 0.6191\n",
      "Epoch 71/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1122 - accuracy: 0.9620 - val_loss: 1.7201 - val_accuracy: 0.6215\n",
      "Epoch 72/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1120 - accuracy: 0.9616 - val_loss: 1.6586 - val_accuracy: 0.6170\n",
      "Epoch 73/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.1127 - accuracy: 0.9616 - val_loss: 1.6912 - val_accuracy: 0.6250\n",
      "Epoch 74/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1052 - accuracy: 0.9646 - val_loss: 1.7192 - val_accuracy: 0.6221\n",
      "Epoch 75/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1024 - accuracy: 0.9651 - val_loss: 1.7242 - val_accuracy: 0.6155\n",
      "Epoch 76/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1063 - accuracy: 0.9629 - val_loss: 1.7454 - val_accuracy: 0.6187\n",
      "Epoch 77/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1012 - accuracy: 0.9647 - val_loss: 1.7547 - val_accuracy: 0.6240\n",
      "Epoch 78/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1012 - accuracy: 0.9647 - val_loss: 1.7159 - val_accuracy: 0.6193\n",
      "Epoch 79/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1069 - accuracy: 0.9639 - val_loss: 1.6734 - val_accuracy: 0.6183\n",
      "Epoch 80/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1021 - accuracy: 0.9655 - val_loss: 1.7369 - val_accuracy: 0.6203\n",
      "Epoch 81/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.1014 - accuracy: 0.9647 - val_loss: 1.6740 - val_accuracy: 0.6166\n",
      "Epoch 82/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0985 - accuracy: 0.9663 - val_loss: 1.7105 - val_accuracy: 0.6177\n",
      "Epoch 83/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0989 - accuracy: 0.9656 - val_loss: 1.7382 - val_accuracy: 0.6180\n",
      "Epoch 84/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0992 - accuracy: 0.9657 - val_loss: 1.7371 - val_accuracy: 0.6229\n",
      "Epoch 85/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0954 - accuracy: 0.9662 - val_loss: 1.7427 - val_accuracy: 0.6183\n",
      "Epoch 86/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0984 - accuracy: 0.9671 - val_loss: 1.7063 - val_accuracy: 0.6191\n",
      "Epoch 87/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0921 - accuracy: 0.9676 - val_loss: 1.7011 - val_accuracy: 0.6161\n",
      "Epoch 88/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.1018 - accuracy: 0.9655 - val_loss: 1.7355 - val_accuracy: 0.6189\n",
      "Epoch 89/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0895 - accuracy: 0.9682 - val_loss: 1.7527 - val_accuracy: 0.6189\n",
      "Epoch 90/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0886 - accuracy: 0.9695 - val_loss: 1.7286 - val_accuracy: 0.6212\n",
      "Epoch 91/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0928 - accuracy: 0.9682 - val_loss: 1.7665 - val_accuracy: 0.6172\n",
      "Epoch 92/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0896 - accuracy: 0.9695 - val_loss: 1.7792 - val_accuracy: 0.6214\n",
      "Epoch 93/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0970 - accuracy: 0.9667 - val_loss: 1.7234 - val_accuracy: 0.6205\n",
      "Epoch 94/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0873 - accuracy: 0.9695 - val_loss: 1.7518 - val_accuracy: 0.6170\n",
      "Epoch 95/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0909 - accuracy: 0.9683 - val_loss: 1.7512 - val_accuracy: 0.6158\n",
      "Epoch 96/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0883 - accuracy: 0.9692 - val_loss: 1.8140 - val_accuracy: 0.6215\n",
      "Epoch 97/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0925 - accuracy: 0.9686 - val_loss: 1.7736 - val_accuracy: 0.6214\n",
      "Epoch 98/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0886 - accuracy: 0.9688 - val_loss: 1.7718 - val_accuracy: 0.6223\n",
      "Epoch 99/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0896 - accuracy: 0.9679 - val_loss: 1.7738 - val_accuracy: 0.6201\n",
      "Epoch 100/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0879 - accuracy: 0.9695 - val_loss: 1.7393 - val_accuracy: 0.6221\n",
      "Epoch 101/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0872 - accuracy: 0.9696 - val_loss: 1.7901 - val_accuracy: 0.6244\n",
      "Epoch 102/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0882 - accuracy: 0.9689 - val_loss: 1.8141 - val_accuracy: 0.6217\n",
      "Epoch 103/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0836 - accuracy: 0.9718 - val_loss: 1.8617 - val_accuracy: 0.6183\n",
      "Epoch 104/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0873 - accuracy: 0.9702 - val_loss: 1.7415 - val_accuracy: 0.6215\n",
      "Epoch 105/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0853 - accuracy: 0.9712 - val_loss: 1.7603 - val_accuracy: 0.6176\n",
      "Epoch 106/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0804 - accuracy: 0.9726 - val_loss: 1.8356 - val_accuracy: 0.6225\n",
      "Epoch 107/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0832 - accuracy: 0.9719 - val_loss: 1.7781 - val_accuracy: 0.6223\n",
      "Epoch 108/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0882 - accuracy: 0.9695 - val_loss: 1.7980 - val_accuracy: 0.6212\n",
      "Epoch 109/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0830 - accuracy: 0.9711 - val_loss: 1.7793 - val_accuracy: 0.6166\n",
      "Epoch 110/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0838 - accuracy: 0.9719 - val_loss: 1.7870 - val_accuracy: 0.6243\n",
      "Epoch 111/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0774 - accuracy: 0.9736 - val_loss: 1.8211 - val_accuracy: 0.6191\n",
      "Epoch 112/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0826 - accuracy: 0.9715 - val_loss: 1.7973 - val_accuracy: 0.6219\n",
      "Epoch 113/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0828 - accuracy: 0.9720 - val_loss: 1.7966 - val_accuracy: 0.6218\n",
      "Epoch 114/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0802 - accuracy: 0.9725 - val_loss: 1.7614 - val_accuracy: 0.6207\n",
      "Epoch 115/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0745 - accuracy: 0.9732 - val_loss: 1.8571 - val_accuracy: 0.6200\n",
      "Epoch 116/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0796 - accuracy: 0.9730 - val_loss: 1.7747 - val_accuracy: 0.6155\n",
      "Epoch 117/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0771 - accuracy: 0.9726 - val_loss: 1.8265 - val_accuracy: 0.6154\n",
      "Epoch 118/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0789 - accuracy: 0.9722 - val_loss: 1.8295 - val_accuracy: 0.6223\n",
      "Epoch 119/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0833 - accuracy: 0.9710 - val_loss: 1.7768 - val_accuracy: 0.6152\n",
      "Epoch 120/200\n",
      "448/448 [==============================] - 72s 162ms/step - loss: 0.0826 - accuracy: 0.9721 - val_loss: 1.8487 - val_accuracy: 0.6233\n",
      "Epoch 121/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0754 - accuracy: 0.9730 - val_loss: 1.7985 - val_accuracy: 0.6204\n",
      "Epoch 122/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0767 - accuracy: 0.9734 - val_loss: 1.8249 - val_accuracy: 0.6200\n",
      "Epoch 123/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0786 - accuracy: 0.9728 - val_loss: 1.8155 - val_accuracy: 0.6208\n",
      "Epoch 124/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0788 - accuracy: 0.9728 - val_loss: 1.7673 - val_accuracy: 0.6243\n",
      "Epoch 125/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0763 - accuracy: 0.9737 - val_loss: 1.8328 - val_accuracy: 0.6250\n",
      "Epoch 126/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0743 - accuracy: 0.9742 - val_loss: 1.8755 - val_accuracy: 0.6210\n",
      "Epoch 127/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0765 - accuracy: 0.9727 - val_loss: 1.8218 - val_accuracy: 0.6210\n",
      "Epoch 128/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0738 - accuracy: 0.9745 - val_loss: 1.8204 - val_accuracy: 0.6198\n",
      "Epoch 129/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0773 - accuracy: 0.9734 - val_loss: 1.8350 - val_accuracy: 0.6236\n",
      "Epoch 130/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0703 - accuracy: 0.9754 - val_loss: 1.8237 - val_accuracy: 0.6211\n",
      "Epoch 131/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0736 - accuracy: 0.9743 - val_loss: 1.8137 - val_accuracy: 0.6190\n",
      "Epoch 132/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0772 - accuracy: 0.9743 - val_loss: 1.8510 - val_accuracy: 0.6242\n",
      "Epoch 133/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0759 - accuracy: 0.9736 - val_loss: 1.8559 - val_accuracy: 0.6295\n",
      "Epoch 134/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0731 - accuracy: 0.9752 - val_loss: 1.8400 - val_accuracy: 0.6236\n",
      "Epoch 135/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0735 - accuracy: 0.9747 - val_loss: 1.8579 - val_accuracy: 0.6253\n",
      "Epoch 136/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0756 - accuracy: 0.9744 - val_loss: 1.8550 - val_accuracy: 0.6212\n",
      "Epoch 137/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0708 - accuracy: 0.9749 - val_loss: 1.8551 - val_accuracy: 0.6187\n",
      "Epoch 138/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0680 - accuracy: 0.9762 - val_loss: 1.8542 - val_accuracy: 0.6187\n",
      "Epoch 139/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0691 - accuracy: 0.9769 - val_loss: 1.8534 - val_accuracy: 0.6189\n",
      "Epoch 140/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0701 - accuracy: 0.9754 - val_loss: 1.8756 - val_accuracy: 0.6236\n",
      "Epoch 141/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0672 - accuracy: 0.9767 - val_loss: 1.8972 - val_accuracy: 0.6180\n",
      "Epoch 142/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0699 - accuracy: 0.9753 - val_loss: 1.8123 - val_accuracy: 0.6230\n",
      "Epoch 143/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0716 - accuracy: 0.9751 - val_loss: 1.8705 - val_accuracy: 0.6177\n",
      "Epoch 144/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0693 - accuracy: 0.9756 - val_loss: 1.8769 - val_accuracy: 0.6179\n",
      "Epoch 145/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0689 - accuracy: 0.9766 - val_loss: 1.8662 - val_accuracy: 0.6215\n",
      "Epoch 146/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0678 - accuracy: 0.9765 - val_loss: 1.8848 - val_accuracy: 0.6190\n",
      "Epoch 147/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0693 - accuracy: 0.9765 - val_loss: 1.9272 - val_accuracy: 0.6166\n",
      "Epoch 148/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0673 - accuracy: 0.9769 - val_loss: 1.8839 - val_accuracy: 0.6205\n",
      "Epoch 149/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0684 - accuracy: 0.9771 - val_loss: 1.8977 - val_accuracy: 0.6240\n",
      "Epoch 150/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0669 - accuracy: 0.9783 - val_loss: 1.8794 - val_accuracy: 0.6207\n",
      "Epoch 151/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0677 - accuracy: 0.9774 - val_loss: 1.8736 - val_accuracy: 0.6222\n",
      "Epoch 152/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0669 - accuracy: 0.9773 - val_loss: 1.8611 - val_accuracy: 0.6158\n",
      "Epoch 153/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0678 - accuracy: 0.9768 - val_loss: 1.8976 - val_accuracy: 0.6223\n",
      "Epoch 154/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0713 - accuracy: 0.9748 - val_loss: 1.8359 - val_accuracy: 0.6191\n",
      "Epoch 155/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0662 - accuracy: 0.9766 - val_loss: 1.8889 - val_accuracy: 0.6229\n",
      "Epoch 156/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0646 - accuracy: 0.9775 - val_loss: 1.9300 - val_accuracy: 0.6172\n",
      "Epoch 157/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0662 - accuracy: 0.9769 - val_loss: 1.8840 - val_accuracy: 0.6190\n",
      "Epoch 158/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0676 - accuracy: 0.9767 - val_loss: 1.9445 - val_accuracy: 0.6233\n",
      "Epoch 159/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0613 - accuracy: 0.9789 - val_loss: 1.9325 - val_accuracy: 0.6228\n",
      "Epoch 160/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0618 - accuracy: 0.9784 - val_loss: 1.9399 - val_accuracy: 0.6240\n",
      "Epoch 161/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0684 - accuracy: 0.9769 - val_loss: 1.8173 - val_accuracy: 0.6226\n",
      "Epoch 162/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0634 - accuracy: 0.9780 - val_loss: 1.9023 - val_accuracy: 0.6230\n",
      "Epoch 163/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0617 - accuracy: 0.9784 - val_loss: 1.8985 - val_accuracy: 0.6176\n",
      "Epoch 164/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0651 - accuracy: 0.9775 - val_loss: 1.9184 - val_accuracy: 0.6225\n",
      "Epoch 165/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0639 - accuracy: 0.9789 - val_loss: 1.8666 - val_accuracy: 0.6201\n",
      "Epoch 166/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0620 - accuracy: 0.9779 - val_loss: 1.9176 - val_accuracy: 0.6223\n",
      "Epoch 167/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0662 - accuracy: 0.9767 - val_loss: 1.9582 - val_accuracy: 0.6203\n",
      "Epoch 168/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0621 - accuracy: 0.9786 - val_loss: 1.9051 - val_accuracy: 0.6198\n",
      "Epoch 169/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0630 - accuracy: 0.9795 - val_loss: 1.8515 - val_accuracy: 0.6165\n",
      "Epoch 170/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0585 - accuracy: 0.9799 - val_loss: 1.8846 - val_accuracy: 0.6179\n",
      "Epoch 171/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0605 - accuracy: 0.9795 - val_loss: 1.8924 - val_accuracy: 0.6158\n",
      "Epoch 172/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0576 - accuracy: 0.9801 - val_loss: 1.9310 - val_accuracy: 0.6203\n",
      "Epoch 173/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0626 - accuracy: 0.9781 - val_loss: 2.0314 - val_accuracy: 0.6190\n",
      "Epoch 174/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0607 - accuracy: 0.9793 - val_loss: 1.9575 - val_accuracy: 0.6161\n",
      "Epoch 175/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0634 - accuracy: 0.9777 - val_loss: 1.9041 - val_accuracy: 0.6214\n",
      "Epoch 176/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0562 - accuracy: 0.9810 - val_loss: 1.8954 - val_accuracy: 0.6198\n",
      "Epoch 177/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0622 - accuracy: 0.9787 - val_loss: 1.9440 - val_accuracy: 0.6212\n",
      "Epoch 178/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0582 - accuracy: 0.9795 - val_loss: 1.8944 - val_accuracy: 0.6228\n",
      "Epoch 179/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0613 - accuracy: 0.9785 - val_loss: 1.9266 - val_accuracy: 0.6239\n",
      "Epoch 180/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0633 - accuracy: 0.9783 - val_loss: 1.8788 - val_accuracy: 0.6170\n",
      "Epoch 181/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 1.9291 - val_accuracy: 0.6200\n",
      "Epoch 182/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0597 - accuracy: 0.9798 - val_loss: 1.8978 - val_accuracy: 0.6165\n",
      "Epoch 183/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0570 - accuracy: 0.9798 - val_loss: 1.9521 - val_accuracy: 0.6215\n",
      "Epoch 184/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0587 - accuracy: 0.9801 - val_loss: 1.9240 - val_accuracy: 0.6221\n",
      "Epoch 185/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0584 - accuracy: 0.9795 - val_loss: 1.9552 - val_accuracy: 0.6183\n",
      "Epoch 186/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0612 - accuracy: 0.9793 - val_loss: 1.9601 - val_accuracy: 0.6184\n",
      "Epoch 187/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0585 - accuracy: 0.9806 - val_loss: 1.9884 - val_accuracy: 0.6232\n",
      "Epoch 188/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0599 - accuracy: 0.9796 - val_loss: 1.9819 - val_accuracy: 0.6233\n",
      "Epoch 189/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0569 - accuracy: 0.9807 - val_loss: 1.9421 - val_accuracy: 0.6261\n",
      "Epoch 190/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0561 - accuracy: 0.9809 - val_loss: 1.9841 - val_accuracy: 0.6222\n",
      "Epoch 191/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0588 - accuracy: 0.9798 - val_loss: 1.9283 - val_accuracy: 0.6264\n",
      "Epoch 192/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0564 - accuracy: 0.9804 - val_loss: 1.9452 - val_accuracy: 0.6215\n",
      "Epoch 193/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0577 - accuracy: 0.9801 - val_loss: 1.9294 - val_accuracy: 0.6190\n",
      "Epoch 194/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0606 - accuracy: 0.9799 - val_loss: 1.9409 - val_accuracy: 0.6189\n",
      "Epoch 195/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0569 - accuracy: 0.9805 - val_loss: 1.9733 - val_accuracy: 0.6207\n",
      "Epoch 196/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0559 - accuracy: 0.9808 - val_loss: 1.9740 - val_accuracy: 0.6222\n",
      "Epoch 197/200\n",
      "448/448 [==============================] - 71s 160ms/step - loss: 0.0546 - accuracy: 0.9808 - val_loss: 1.9388 - val_accuracy: 0.6211\n",
      "Epoch 198/200\n",
      "448/448 [==============================] - 72s 160ms/step - loss: 0.0562 - accuracy: 0.9801 - val_loss: 1.9800 - val_accuracy: 0.6264\n",
      "Epoch 199/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0551 - accuracy: 0.9802 - val_loss: 1.9983 - val_accuracy: 0.6221\n",
      "Epoch 200/200\n",
      "448/448 [==============================] - 71s 159ms/step - loss: 0.0553 - accuracy: 0.9809 - val_loss: 1.9883 - val_accuracy: 0.6233\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network/model\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=200,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model structure in jason file\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model_3_epochs200.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# save trained model weight in .h5 file\n",
    "emotion_model.save_weights('emotion_model_3_epochs200.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
